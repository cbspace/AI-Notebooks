{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d968b8b7-56d4-49c1-9bae-ab6eb5ca730b",
   "metadata": {},
   "source": [
    "# Retrieveal Augmented Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec87cda0-21a9-4c7f-878d-8537f102fa03",
   "metadata": {},
   "source": [
    "Retrieval Augmented Generation is a useful way to tailor the knowledge of an LLM to your own documents and knowledge base. In this notebook I will be creating a RAG model using the Huggingface Transformers library. This RAG model pretrained on Wikipedia text for retrieval.\n",
    "\n",
    "Useful Links:\n",
    "<ul><li><a href=\"https://huggingface.co/transformers/v3.3.1/model_doc/rag.html\" target=\"_blank\">HF Transformers RAG Documentation</a></li>\n",
    "    <li><a href=\"https://arxiv.org/abs/2005.11401\" target=\"_blank\">RAG Paper</a></li>\n",
    "</ul>\n",
    "\n",
    "Required Python Libraries:\n",
    "<ul><li>transformers</li> \n",
    "    <li>faiss</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c298289b-e33e-47d8-b09f-f428d5500d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It's always a good idea to make sure you have the latest packag versions\n",
    "#!pip install -U transformers faiss datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6eed6e26-a407-4986-86c5-77b7c30c7a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "from transformers.utils import logging\n",
    "logging.set_verbosity_error() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3dc9ee74-8900-406b-be1a-22cd130ad0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RagTokenizer, RagRetriever, RagTokenForGeneration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c0c156-78c0-4f41-913d-2aeefe89393f",
   "metadata": {},
   "source": [
    "This pretrained model uses the \"wiki_dpr\" dataset which contains 21M Wikipedia articles from 2018. The dataset is large in terms of disk space at around 78GB however the retrieval indexes are compressed to significantly reduce the required space. There is some loss of accuracy in the compression which needs to be taken into account when deploying RAG. Compression can significantly reduce the amount of disk space and RAM required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "742c8a26-73e5-4c3b-af16-382f98cfe119",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0efb7fb538d54d55a03c82fca125e531",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset shards:   0%|          | 0/161 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba387323dc154c4a99cdc0d7758199d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset shards:   0%|          | 0/161 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = \"facebook/rag-token-nq\"\n",
    "\n",
    "tokenizer = RagTokenizer.from_pretrained(model_name)\n",
    "retriever = RagRetriever.from_pretrained(model_name, dataset=\"wiki_dpr\", index_name=\"compressed\")\n",
    "model = RagTokenForGeneration.from_pretrained(model_name, retriever=retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af4f19c1-7fea-4da8-b056-b284ccfcd393",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " canberra\n"
     ]
    }
   ],
   "source": [
    "input_dict = tokenizer.prepare_seq2seq_batch(\"What is the capital of Australia?\", return_tensors=\"pt\") \n",
    "\n",
    "generated = model.generate(input_ids=input_dict[\"input_ids\"]) \n",
    "print(tokenizer.batch_decode(generated, skip_special_tokens=True)[0]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df01336-3838-4dcf-973b-696218a66a05",
   "metadata": {},
   "source": [
    "In conclusion RAG is a highly effective way to delploy LLMs in an enterprise setting. New RAG technologies are emerging every day such as agents and tool usage. RAG is currently one of the most popular uses of LLMs."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
